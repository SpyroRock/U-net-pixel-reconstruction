{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U_net_pixel_reconstruction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxo6r+OA5c8MDnIl7Oyrvn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpyroRock/U-net-pixel-reconstruction/blob/master/U_net_pixel_reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ddy_nWjxBSB",
        "outputId": "0e902858-7b73-43da-8c96-fa327fc210ae"
      },
      "source": [
        "!git clone https://github.com/SpyroRock/U-net-pixel-reconstruction"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'U-net-pixel-reconstruction'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 2044 (delta 5), reused 1 (delta 0), pack-reused 2033\u001b[K\n",
            "Receiving objects: 100% (2044/2044), 250.52 MiB | 33.25 MiB/s, done.\n",
            "Resolving deltas: 100% (1146/1146), done.\n",
            "Checking out files: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUWs3n5LxWHp",
        "outputId": "caa19770-6b49-4166-ae99-dae6cc4fb926"
      },
      "source": [
        "%cd U-net-pixel-reconstruction"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/U-net-pixel-reconstruction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "506mibGMyGtS",
        "outputId": "6342e6ee-98f5-454c-d7b6-8e10a93ef2bb"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/95/274190b39950e1e9eef4b071acefea832ac3e2c19bb4b442fa54f3214d2e/tensorflow-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (51.1MB)\n",
            "\u001b[K     |████████████████████████████████| 51.1MB 61kB/s \n",
            "\u001b[?25hCollecting keras==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 53.0MB/s \n",
            "\u001b[?25hCollecting keras-segmentation==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/f0/b8def71a219c6a21f5201727082e846c560817712b3484e8f0c834c9c0e6/keras_segmentation-0.3.0.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.8.1)\n",
            "Collecting tensorboard<1.10.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/1f/3da43860db614e294a034e42d4be5c8f7f0d2c75dc1c428c541116d8cdab/tensorboard-1.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.36.2)\n",
            "Collecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->-r requirements.txt (line 2)) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->-r requirements.txt (line 2)) (3.13)\n",
            "Collecting keras-applications==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Collecting imageio==2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug==0.2.9 in /usr/local/lib/python3.6/dist-packages (from keras-segmentation==0.3.0->-r requirements.txt (line 3)) (0.2.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from keras-segmentation==0.3.0->-r requirements.txt (line 3)) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-segmentation==0.3.0->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.3.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.5.0->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (0.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (4.4.2)\n",
            "Building wheels for collected packages: keras-segmentation\n",
            "  Building wheel for keras-segmentation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-segmentation: filename=keras_segmentation-0.3.0-cp36-none-any.whl size=29072 sha256=5bc0dc38b7630565eda5d9583d4bc4ec313eddc8cf9fc1efd305dec0f537c40a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/bb/c0/6aad88b38f6e46db048bed4cccb904a5897055a8ab6fbd4dfc\n",
            "Successfully built keras-segmentation\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.25.0 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, setuptools, tensorflow, keras-applications, keras-preprocessing, keras, imageio, keras-segmentation\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: setuptools 53.0.0\n",
            "    Uninstalling setuptools-53.0.0:\n",
            "      Successfully uninstalled setuptools-53.0.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.5.0 keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 keras-segmentation-0.3.0 setuptools-39.1.0 tensorboard-1.9.0 tensorflow-1.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzIjLlivyMg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e852cb-6f72-438e-c518-fe0a30ae8d0b"
      },
      "source": [
        "%cd U-net-pixel-reconstruction\n",
        "\n",
        "from unet_model_construction import get_unet\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from numpy import load, save\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/U-net-pixel-reconstruction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl26IoRj26fr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f943fe66-0ee6-4da5-eb5f-15cccc107920"
      },
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "img_height_test = 256\n",
        "img_width_test = 256\n",
        "\n",
        "speckle_data = load('speckle_cluster_case2.npy')\n",
        "print(speckle_data.shape)\n",
        "speckle_labels = load('symbol_cluster_case2.npy')\n",
        "print(speckle_labels.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(180, 256, 256)\n",
            "(180, 256, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMraJc_J4I9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b95ec4-6c48-42ee-8c8e-5d992550249d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(speckle_data, speckle_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(-1, img_height, img_width, 1)\n",
        "X_test = X_test.reshape(-1, img_height, img_width, 1)\n",
        "input_shape = (img_height, img_width, 1)\n",
        "\n",
        "y_train = y_train.reshape(-1, img_height_test, img_width_test, 1)\n",
        "y_test = y_test.reshape(-1, img_height_test, img_width_test, 1)\n",
        "input_shape_test = (img_height_test, img_width_test, 1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(162, 256, 256, 1)\n",
            "(162, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBMupUde4MLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f5d1d75-ae33-425f-b44a-948e7f2f79d7"
      },
      "source": [
        "# checkpoint\n",
        "#checkpoint_filepath = 'weights.{epoch:02d}-{accuracy:.2f}.hdf5'\n",
        "checkpoint_filepath = '/content/U-net-pixel-reconstruction/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
        "\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath,\n",
        "                                                               save_weights_only = True,\n",
        "                                                               verbose=1)\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "reconstruction = get_unet(input_shape, n_filters = 32, dropout = 0.1, batchnorm = True)\n",
        "\n",
        "reconstruction.fit(X_train, y_train, \n",
        "                   batch_size = 10,\n",
        "                   epochs = 10500,\n",
        "                   verbose = 1,\n",
        "                   validation_data = (X_test, y_test),    \n",
        "                   callbacks = [model_checkpoint_callback])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 32) 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128, 128, 32) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 64) 18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 64, 64)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 128)  73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 128)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  295168      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 256)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1180160     dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  1179904     activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 512)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  1179904     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  295040      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64, 64, 256)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 128)  295040      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 73792       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128, 128, 128 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 64) 73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 18464       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 256, 64) 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 32) 18464       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 256, 256, 32) 128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 256, 256, 32) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,708,321\n",
            "Trainable params: 4,705,377\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n",
            "Train on 162 samples, validate on 18 samples\n",
            "Epoch 1/10500\n",
            "162/162 [==============================] - 381s 2s/step - loss: 1.1812 - acc: 0.4331 - val_loss: 1.5517 - val_acc: 0.4092\n",
            "Epoch 2/10500\n",
            "162/162 [==============================] - 381s 2s/step - loss: 1.1796 - acc: 0.4310 - val_loss: 1.5496 - val_acc: 0.4082\n",
            "Epoch 3/10500\n",
            " 50/162 [========>.....................] - ETA: 4:14 - loss: 1.1826 - acc: 0.4045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3c95b751cb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                    \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                    validation_data = (X_test, y_test)) # Data on which to evaluate the loss and any model metrics at the end of each epoch. \n\u001b[0m\u001b[1;32m     22\u001b[0m                                                        \u001b[0;31m# The model will not be trained on this data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                        \u001b[0;31m# This could be a list (x_val, y_val) or a list (x_val, y_val, val_sample_weights).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JtdYvvo4pFi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}