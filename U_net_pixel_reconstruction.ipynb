{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U_net_pixel_reconstruction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJHmVZ0cPbecz1BBSmcfbI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpyroRock/U-net-pixel-reconstruction/blob/master/U_net_pixel_reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ddy_nWjxBSB",
        "outputId": "37fa2e59-d473-4543-92e2-ac76d799e5a5"
      },
      "source": [
        "!git clone https://github.com/SpyroRock/U-net-pixel-reconstruction"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'U-net-pixel-reconstruction'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 2047 (delta 7), reused 1 (delta 0), pack-reused 2033\u001b[K\n",
            "Receiving objects: 100% (2047/2047), 250.52 MiB | 33.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1148/1148), done.\n",
            "Checking out files: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUWs3n5LxWHp",
        "outputId": "3e997974-82e6-4daa-d5a4-076add7a47aa"
      },
      "source": [
        "%cd U-net-pixel-reconstruction"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/U-net-pixel-reconstruction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "506mibGMyGtS",
        "outputId": "afa3f0a5-ad75-49e3-ceaa-235ecb3e42af"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/95/274190b39950e1e9eef4b071acefea832ac3e2c19bb4b442fa54f3214d2e/tensorflow-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (51.1MB)\n",
            "\u001b[K     |████████████████████████████████| 51.1MB 60kB/s \n",
            "\u001b[?25hCollecting keras==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 54.6MB/s \n",
            "\u001b[?25hCollecting keras-segmentation==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/f0/b8def71a219c6a21f5201727082e846c560817712b3484e8f0c834c9c0e6/keras_segmentation-0.3.0.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Collecting tensorboard<1.10.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/1f/3da43860db614e294a034e42d4be5c8f7f0d2c75dc1c428c541116d8cdab/tensorboard-1.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (3.12.4)\n",
            "Collecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.9.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting keras-applications==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->-r requirements.txt (line 2)) (2.10.0)\n",
            "Collecting keras-preprocessing==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->-r requirements.txt (line 2)) (3.13)\n",
            "Collecting imageio==2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug==0.2.9 in /usr/local/lib/python3.6/dist-packages (from keras-segmentation==0.3.0->-r requirements.txt (line 3)) (0.2.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from keras-segmentation==0.3.0->-r requirements.txt (line 3)) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-segmentation==0.3.0->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.5.0->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (0.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation==0.3.0->-r requirements.txt (line 3)) (4.4.2)\n",
            "Building wheels for collected packages: keras-segmentation\n",
            "  Building wheel for keras-segmentation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-segmentation: filename=keras_segmentation-0.3.0-cp36-none-any.whl size=29072 sha256=6551703c706874ebcb1ad67d00f51e829e4e20c36d38b76c8022214ae7c83bc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/bb/c0/6aad88b38f6e46db048bed4cccb904a5897055a8ab6fbd4dfc\n",
            "Successfully built keras-segmentation\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.25.0 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, setuptools, tensorflow, keras-applications, keras-preprocessing, keras, imageio, keras-segmentation\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: setuptools 53.0.0\n",
            "    Uninstalling setuptools-53.0.0:\n",
            "      Successfully uninstalled setuptools-53.0.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.5.0 keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 keras-segmentation-0.3.0 setuptools-39.1.0 tensorboard-1.9.0 tensorflow-1.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzIjLlivyMg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa0f012-8089-4add-9894-2ac4b3df4866"
      },
      "source": [
        "%cd U-net-pixel-reconstruction\n",
        "\n",
        "from unet_model_construction import get_unet\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from numpy import load, save\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/U-net-pixel-reconstruction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl26IoRj26fr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4e6b23-8826-4cce-cd9d-92dc29a0ad67"
      },
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "img_height_test = 256\n",
        "img_width_test = 256\n",
        "\n",
        "speckle_data = load('speckle_cluster_case2.npy')\n",
        "print(speckle_data.shape)\n",
        "speckle_labels = load('symbol_cluster_case2.npy')\n",
        "print(speckle_labels.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(180, 256, 256)\n",
            "(180, 256, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMraJc_J4I9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce89c58-e034-4a8b-ed50-ea50a6488ea7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(speckle_data, speckle_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(-1, img_height, img_width, 1)\n",
        "X_test = X_test.reshape(-1, img_height, img_width, 1)\n",
        "input_shape = (img_height, img_width, 1)\n",
        "\n",
        "y_train = y_train.reshape(-1, img_height_test, img_width_test, 1)\n",
        "y_test = y_test.reshape(-1, img_height_test, img_width_test, 1)\n",
        "input_shape_test = (img_height_test, img_width_test, 1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(162, 256, 256, 1)\n",
            "(162, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBMupUde4MLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d37830-ce92-4ce3-ad27-9aae61046923"
      },
      "source": [
        "# checkpoint\n",
        "#checkpoint_filepath = 'weights.{epoch:02d}-{accuracy:.2f}.hdf5'\n",
        "checkpoint_filepath = '/content/U-net-pixel-reconstruction/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
        "\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath,\n",
        "                                                               save_weights_only = True,\n",
        "                                                               verbose=1)\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "reconstruction = get_unet(input_shape, n_filters = 32, dropout = 0.1, batchnorm = True)\n",
        "\n",
        "reconstruction.fit(X_train, y_train, \n",
        "                   batch_size = 10,\n",
        "                   epochs = 100,\n",
        "                   verbose = 1,\n",
        "                   validation_data = (X_test, y_test),    \n",
        "                   callbacks = [model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 32) 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128, 128, 32) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 64) 18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 64, 64)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 128)  73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 128)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  295168      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 256)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1180160     dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  1179904     activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 512)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  1179904     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  295040      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64, 64, 256)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 128)  295040      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 73792       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128, 128, 128 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 64) 73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 18464       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 256, 64) 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 32) 18464       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 256, 256, 32) 128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 256, 256, 32) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,708,321\n",
            "Trainable params: 4,705,377\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n",
            "Train on 162 samples, validate on 18 samples\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 365s 2s/step - loss: 0.7993 - acc: 0.3160 - val_loss: 0.7991 - val_acc: 0.1345\n",
            "\n",
            "Epoch 00001: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 363s 2s/step - loss: 0.7976 - acc: 0.3187 - val_loss: 0.7976 - val_acc: 0.1330\n",
            "\n",
            "Epoch 00002: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 358s 2s/step - loss: 0.7958 - acc: 0.3197 - val_loss: 0.7954 - val_acc: 0.1344\n",
            "\n",
            "Epoch 00003: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 357s 2s/step - loss: 0.7946 - acc: 0.3222 - val_loss: 0.7929 - val_acc: 0.1363\n",
            "\n",
            "Epoch 00004: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 359s 2s/step - loss: 0.7935 - acc: 0.3253 - val_loss: 0.7907 - val_acc: 0.1375\n",
            "\n",
            "Epoch 00005: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 359s 2s/step - loss: 0.7925 - acc: 0.3258 - val_loss: 0.7885 - val_acc: 0.1392\n",
            "\n",
            "Epoch 00006: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 358s 2s/step - loss: 0.7902 - acc: 0.3287 - val_loss: 0.7862 - val_acc: 0.1409\n",
            "\n",
            "Epoch 00007: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 358s 2s/step - loss: 0.7892 - acc: 0.3303 - val_loss: 0.7842 - val_acc: 0.1422\n",
            "\n",
            "Epoch 00008: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 358s 2s/step - loss: 0.7881 - acc: 0.3314 - val_loss: 0.7820 - val_acc: 0.1445\n",
            "\n",
            "Epoch 00009: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 359s 2s/step - loss: 0.7864 - acc: 0.3342 - val_loss: 0.7797 - val_acc: 0.1467\n",
            "\n",
            "Epoch 00010: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 361s 2s/step - loss: 0.7853 - acc: 0.3343 - val_loss: 0.7777 - val_acc: 0.1486\n",
            "\n",
            "Epoch 00011: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 359s 2s/step - loss: 0.7829 - acc: 0.3382 - val_loss: 0.7751 - val_acc: 0.1520\n",
            "\n",
            "Epoch 00012: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 361s 2s/step - loss: 0.7828 - acc: 0.3401 - val_loss: 0.7727 - val_acc: 0.1551\n",
            "\n",
            "Epoch 00013: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 361s 2s/step - loss: 0.7804 - acc: 0.3419 - val_loss: 0.7701 - val_acc: 0.1586\n",
            "\n",
            "Epoch 00014: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 355s 2s/step - loss: 0.7793 - acc: 0.3437 - val_loss: 0.7681 - val_acc: 0.1609\n",
            "\n",
            "Epoch 00015: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 353s 2s/step - loss: 0.7784 - acc: 0.3454 - val_loss: 0.7660 - val_acc: 0.1638\n",
            "\n",
            "Epoch 00016: saving model to /content/U-net-pixel-reconstruction/cp.ckpt\n",
            "Epoch 17/100\n",
            " 40/162 [======>.......................] - ETA: 4:15 - loss: 0.7787 - acc: 0.3589"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JtdYvvo4pFi"
      },
      "source": [
        "reconstruction.load_weights(checkpoint_filepath)\n",
        "\n",
        "score = reconstruction.evaluate(X_test, y_test, verbose = 0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test acuracy:', score[1])\n",
        "\n",
        "y_predicted = reconstruction.predict(X_test)\n",
        "\n",
        "extract = Model(reconstruction.inputs, reconstruction.layers[-1].output) \n",
        "features = extract.predict(X_test)\n",
        "print(features.shape)\n",
        "save('features_data.npy', features)\n",
        "save('features_predicted.npy', y_predicted)\n",
        "\n",
        "reconstruction.save('reconstruction_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzmCf7TUezg_"
      },
      "source": [
        "import numpy as np \n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import load\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "\n",
        "#pickle_in = open('reconstruction.pkl', 'rb')\n",
        "#reconstructor = pickle.load(pickle_in)\n",
        "\n",
        "features_symbol = load('features_data.npy')\n",
        "print(tf.constant(features_symbol))\n",
        "print(features_symbol.shape)\n",
        "features_symbol_predicted = load('features_predicted.npy')\n",
        "print(tf.constant(features_symbol_predicted))\n",
        "print(features_symbol_predicted.shape)\n",
        "\n",
        "#print(features_symbol[10, :, :, 0])\n",
        "\n",
        "#plt.imshow(features_symbol[5, :, :, 0], cmap='gray')\n",
        "#plt.show()\n",
        "print(np.min(features_symbol_predicted[17, :, :, 0]))\n",
        "print(np.max(features_symbol_predicted[17, :, :, 0]))\n",
        "plt.imshow(features_symbol_predicted[17, :, :, 0], cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}